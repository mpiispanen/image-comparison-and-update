name: Visual Diff and PR Report

on:
  pull_request:
    types: [opened, synchronize]
  workflow_dispatch:
    inputs:
      test_scenario:
        description: 'Test scenario to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - baseline
          - changed
          - mixed

permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  visual-diff:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        scenario: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.test_scenario == 'all' && fromJson('["baseline", "changed", "mixed"]') || github.event_name == 'workflow_dispatch' && fromJson(format('["{0}"]', github.event.inputs.test_scenario)) || fromJson('["baseline", "changed", "mixed"]') }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        lfs: true
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Install NVIDIA FLIP for image comparison
      run: |
        # Install NVIDIA FLIP from PyPI for high-fidelity image comparison
        pip install flip-evaluator
        flip --help
    
    - name: Setup Python for test execution
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install Pillow numpy
    
    - name: Create necessary directories
      run: |
        mkdir -p outputs
        mkdir -p diffs
        mkdir -p golden
    
    - name: Generate test outputs
      run: |
        # Use the matrix scenario value
        export TEST_SCENARIO="${{ matrix.scenario }}"
        
        echo "Running test scenario: $TEST_SCENARIO"
        
        # Run the application's test suite to generate output images
        python generate_test_images.py
    
    - name: Compare images and generate diffs
      id: compare
      run: |
        # Initialize variables
        CHANGED_IMAGES=""
        CHANGES_DETECTED=false
        
        # Create comparison report with summary table
        echo "# Visual Regression Test Results - Scenario: ${{ matrix.scenario }}" > comparison_report.md
        echo "" >> comparison_report.md
        echo "**Test Scenario:** \`${{ matrix.scenario }}\` - $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> comparison_report.md
        echo "" >> comparison_report.md
        echo "## Summary" >> comparison_report.md
        echo "" >> comparison_report.md
        echo "| File | Status | FLIP Mean Error | Result |" >> comparison_report.md
        echo "|------|--------|-----------------|--------|" >> comparison_report.md
        
        # Initialize summary data
        summary_data=""
        
        # Process each output image
        for output_file in outputs/*.png; do
          if [ ! -f "$output_file" ]; then
            echo "No output images found"
            continue
          fi
          
          filename=$(basename "$output_file")
          golden_file="golden/$filename"
          diff_file="diffs/diff_$filename"
          
          echo "Processing $filename..."
          
          # Check if golden image exists
          if [ ! -f "$golden_file" ]; then
            # New image - no golden master exists
            summary_data="$summary_data| \`$filename\` | üÜï New | N/A | Needs acceptance |\n"
            
            CHANGED_IMAGES="$CHANGED_IMAGES $filename"
            CHANGES_DETECTED=true
          else
            # Fetch the specific golden LFS file
            git lfs pull --include "$golden_file"
            
            # Compare using NVIDIA FLIP for high-fidelity comparison
            # FLIP outputs difference metrics and generates diff images
            basename_no_ext=$(basename "$filename" .png)
            diff_basename="diff_${basename_no_ext}"
            stats_file="diffs/${diff_basename}_stats.txt"
            
            # Debug: Print the command that will be executed
            echo "Variables:"
            echo "  golden_file: '$golden_file'"
            echo "  output_file: '$output_file'"
            echo "  diff_basename: '$diff_basename'"
            echo "  stats_file: '$stats_file'"
            echo "Golden file exists: $([ -f "$golden_file" ] && echo 'YES' || echo 'NO')"
            echo "Output file exists: $([ -f "$output_file" ] && echo 'YES' || echo 'NO')"
            echo ""
            
            # Ensure both files exist before running FLIP
            if [ ! -f "$golden_file" ]; then
              echo "Error: Golden file does not exist: $golden_file"
              continue
            fi
            if [ ! -f "$output_file" ]; then
              echo "Error: Output file does not exist: $output_file"
              continue
            fi
            
            # Use enhanced FLIP parameters for comprehensive statistics
            echo "Running FLIP command: flip -r '$golden_file' -t '$output_file' -d diffs -b '$diff_basename' -v 2 -txt"
            
            # Run FLIP with enhanced verbosity and text output for detailed statistics
            flip_output=$(flip -r "$golden_file" -t "$output_file" -d diffs -b "$diff_basename" -v 2 -txt 2>&1)
            flip_exit_code=$?
            
            echo "FLIP exit code: $flip_exit_code"
            echo "FLIP output: $flip_output"
            
            # Check if FLIP command succeeded
            if [ $flip_exit_code -ne 0 ]; then
              echo "Error: FLIP command failed with exit code $flip_exit_code"
              echo "Error output: $flip_output"
              summary_data="$summary_data| \`$filename\` | ‚ùå Error | N/A | FLIP failed |\n"
              continue
            fi
            
            # Extract comprehensive FLIP statistics from the output
            mean_error=$(echo "$flip_output" | grep "Mean:" | awk '{print $2}')
            median_error=$(echo "$flip_output" | grep "Weighted median:" | awk '{print $3}')
            q1_error=$(echo "$flip_output" | grep "1st weighted quartile:" | awk '{print $4}')
            q3_error=$(echo "$flip_output" | grep "3rd weighted quartile:" | awk '{print $4}')
            min_error=$(echo "$flip_output" | grep "Min:" | awk '{print $2}')
            max_error=$(echo "$flip_output" | grep "Max:" | awk '{print $2}')
            ppd=$(echo "$flip_output" | grep "Pixels per degree:" | awk '{print $4}')
            eval_time=$(echo "$flip_output" | grep "Evaluation time:" | awk '{print $3}')
            
            # Check if there's any meaningful difference (FLIP error > 0.001)
            # Using awk for floating point comparison
            is_different=$(echo "$mean_error" | awk '{if ($1 > 0.001) print "yes"; else print "no"}')
            
            if [ "$is_different" = "yes" ]; then
              summary_data="$summary_data| \`$filename\` | üîÑ Changed | $mean_error | Needs review |\n"
              CHANGED_IMAGES="$CHANGED_IMAGES $filename"
              CHANGES_DETECTED=true
            else
              summary_data="$summary_data| \`$filename\` | ‚úÖ Passed | $mean_error | No changes |\n"
            fi
          fi
        done
        
        # Add summary data to report
        echo -e "$summary_data" >> comparison_report.md
        echo "" >> comparison_report.md
        
        # Add detailed results for changed/new images
        echo "## Detailed Results" >> comparison_report.md
        echo "" >> comparison_report.md
        
        # Note: Images will be available in workflow artifacts for download
        echo "ARTIFACT_DOWNLOAD_INFO" >> comparison_report.md
        
        # Set outputs for next steps
        echo "changes_detected=$CHANGES_DETECTED" >> $GITHUB_OUTPUT
        echo "changed_images=$CHANGED_IMAGES" >> $GITHUB_OUTPUT
        
        # If no changes, add a success message
        if [ "$CHANGES_DETECTED" = "false" ]; then
          echo "‚úÖ **All visual tests passed!** No differences detected." >> comparison_report.md
        fi
    
    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      with:
        name: visual-test-results-${{ matrix.scenario }}-${{ github.event.pull_request.number || github.run_number }}
        path: |
          outputs/
          diffs/
          golden/
          comparison_report.md
        retention-days: 30
    
    - name: Generate comprehensive comparison report
      id: generate_report
      run: |
        # Read the current comparison report
        if [ -f comparison_report.md ]; then
          # Update the comparison report with artifact download information
          sed -i 's/ARTIFACT_DOWNLOAD_INFO/## üñºÔ∏è Image Files Available for Download\n\nSince images cannot be directly displayed in GitHub PR comments, all comparison images are available in the workflow artifacts:\n\nüì¶ **[Download Complete Results](https:\/\/github.com\/${{ github.repository }}\/actions\/runs\/${{ github.run_id }})**\n\n### Artifact Contents:\n- **`outputs\/`** - New test images generated by your changes\n- **`diffs\/`** - Visual difference highlights (red areas show changes)\n- **`golden\/`** - Current golden master images for comparison\n- **`comparison_report.md`** - This detailed comparison report\n\n### Manual Review Process:\n1. Click the download link above\n2. Download the `visual-test-results-${{ matrix.scenario }}-${{ github.event.pull_request.number || github.run_number }}` artifact\n3. Extract the ZIP file to access all images\n4. Compare files side by side:\n   - `outputs\/image-name.png` (your new version)\n   - `golden\/image-name.png` (current golden master)\n   - `diffs\/diff_image-name.png` (highlighted differences)\n5. If changes are intentional, use `\/accept-image <filename>` to update golden masters/' comparison_report.md
          
          echo "Enhanced comparison report generated"
        else
          echo "No comparison report found"
        fi
    
    - name: Debug outputs before commenting
      run: |
        echo "=== Debug Step Outputs ==="
        echo "changes_detected: '${{ steps.compare.outputs.changes_detected }}'"
        echo "changed_images: '${{ steps.compare.outputs.changed_images }}'"
        echo "========================="

    - name: Comment PR with results
      if: steps.compare.outputs.changes_detected == 'true'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('comparison_report.md', 'utf8');
          
          // Clean up old bot comments for this scenario first
          const comments = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number
          });
          
          const botComments = comments.data.filter(comment => 
            comment.user.type === 'Bot' && 
            (comment.body.includes('Visual Regression Test Results - Scenario: ${{ matrix.scenario }}') ||
             (comment.body.includes('Visual Regression Test Results') && 
              comment.body.includes('Scenario: ${{ matrix.scenario }}')))
          );
          
          // Delete old bot comments to avoid confusion
          for (const comment of botComments) {
            try {
              await github.rest.issues.deleteComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: comment.id
              });
              console.log(`Deleted old bot comment: ${comment.id}`);
            } catch (error) {
              console.log(`Failed to delete comment ${comment.id}: ${error.message}`);
            }
          }
          
          // Always create a new comment
          await github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
            body: report
          });
    
    - name: Comment PR with success
      if: steps.compare.outputs.changes_detected == 'false'
      uses: actions/github-script@v7
      with:
        script: |
          const report = "‚úÖ **Visual tests passed for scenario \`${{ matrix.scenario }}\`!** No differences detected.\n\n**Test Scenario:** \`${{ matrix.scenario }}\` - " + new Date().toISOString().replace('T', ' ').substr(0, 19) + " UTC";
          
          // Clean up old bot comments for this scenario first
          const comments = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number
          });
          
          const botComments = comments.data.filter(comment => 
            comment.user.type === 'Bot' && 
            (comment.body.includes('Visual Regression Test Results - Scenario: ${{ matrix.scenario }}') ||
             comment.body.includes('Visual tests passed for scenario `${{ matrix.scenario }}`') ||
             (comment.body.includes('Visual Regression Test Results') && 
              comment.body.includes('Scenario: ${{ matrix.scenario }}')))
          );
          
          // Delete old bot comments to avoid confusion
          for (const comment of botComments) {
            try {
              await github.rest.issues.deleteComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: comment.id
              });
              console.log(`Deleted old bot comment: ${comment.id}`);
            } catch (error) {
              console.log(`Failed to delete comment ${comment.id}: ${error.message}`);
            }
          }
          
          // Always create a new comment
          await github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
            body: report
          });

