# Visual Regression Testing with Git LFS

A robust, LFS-aware GitHub Actions workflow system for visual regression testing. This system handles multiple output images, uses NVIDIA's flip for high-fidelity comparison, and correctly stores final "golden" images using Git LFS to avoid bloating the main repository.

## Features

- **LFS-Aware Storage**: Automatically handles large image files using Git LFS
- **High-Fidelity Comparison**: Uses NVIDIA flip for precise image comparison
- **Interactive Workflow**: Accept/reject changes via PR comments
- **Artifact-Based Review**: Complete image packages with manual comparison workflow
- **Detailed Statistics**: FLIP-based comparison metrics and comprehensive reporting
- **Security**: Permission checks for image acceptance

## Prerequisites

The repository must be configured to use Git LFS for image file types:

```bash
# Install Git LFS
git lfs install

# Track image files (already configured in .gitattributes)
git lfs track "golden/**/*.png"
git lfs track "golden/**/*.jpg" 
git lfs track "golden/**/*.jpeg"
```

## Workflow Overview

### 1. Visual Diff and PR Report

**Trigger**: On every pull request

**Process**:
1. Runs your test suite to generate output images in `outputs/` directory
2. Compares each output against its golden master using NVIDIA flip
3. Generates visual diff images in `diffs/` directory  
4. Posts comprehensive comparison report as PR comment with detailed statistics
5. Uploads complete artifact package including outputs, diffs, golden images, and report

**Artifact-Based Review**:
Since GitHub doesn't support direct image embedding in PR comments, all images are provided via downloadable artifacts:

```markdown
## üñºÔ∏è Image Files Available for Download

üì¶ [Download Complete Results](https://github.com/owner/repo/actions/runs/123)

### Artifact Contents:
- `outputs/` - New test images generated by your changes
- `diffs/` - Visual difference highlights (red areas show changes)
- `golden/` - Current golden master images for comparison  
- `comparison_report.md` - Complete comparison report with detailed statistics

### Manual Review Process:
1. Download and extract the artifact ZIP file
2. Compare files side by side using your preferred image viewer
3. Use `/accept-image <filename>` to update golden masters for approved changes
```

### 2. Accept New Golden Image

**Trigger**: Comment `/accept-image <filename>` on PR

**Process**:
1. Validates commenter has write permissions
2. Downloads artifacts from visual diff workflow
3. Moves accepted image to `golden/` directory
4. Commits and pushes using Git LFS
5. Confirms acceptance via PR comment

## Usage

### Test Scenarios

The workflow supports different test scenarios to help verify both passing and failing cases:

**Available scenarios:**
- `baseline`: Generates consistent images that match golden masters (all tests pass)
- `changed`: Generates modified images that differ from golden masters (all tests fail)  
- `mixed`: Generates a mix where some images pass and some fail

**Running scenarios:**

1. **Via GitHub Actions UI** (recommended):
   - Go to Actions ‚Üí Visual Diff and PR Report ‚Üí Run workflow
   - Select the desired test scenario from the dropdown
   - Click "Run workflow"

2. **Via local testing**:
   ```bash
   # Run specific scenario
   python test_scenarios.py baseline
   python test_scenarios.py changed
   python test_scenarios.py mixed
   
   # Run all scenarios
   python test_scenarios.py
   ```

3. **Via environment variable**:
   ```bash
   TEST_SCENARIO=changed python generate_test_images.py
   ```

### Running Tests

The workflow automatically runs `generate_test_images.py` to create test outputs. Customize this script for your application:

```python
# Your test suite should populate outputs/ directory
def run_your_tests():
    # Generate screenshots, renders, etc.
    save_image("outputs/ui-component.png", your_image_data)
```

### Comment Behavior

The workflow now creates **new comments** for each run instead of updating existing ones. Old bot comments are automatically cleaned up to prevent confusion. This ensures:

- Each test run gets a fresh, timestamped comment
- No confusion from outdated results
- Clear history of test runs in the PR

### Accepting Changes

When the workflow detects visual changes, comment on the PR:

```
/accept-image ui-main-screen.png
```

This will:
- Move the new image to `golden/ui-main-screen.png`
- Commit it with Git LFS
- Update the PR automatically

### Directory Structure

```
‚îú‚îÄ‚îÄ .gitattributes          # Git LFS configuration
‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ   ‚îú‚îÄ‚îÄ visual-diff.yml     # Main comparison workflow
‚îÇ   ‚îî‚îÄ‚îÄ accept-image.yml    # Image acceptance workflow
‚îú‚îÄ‚îÄ generate_test_images.py # Sample test script
‚îú‚îÄ‚îÄ outputs/                # Generated test images (temporary)
‚îú‚îÄ‚îÄ diffs/                  # Visual diff images (temporary)
‚îî‚îÄ‚îÄ golden/                 # Reference images (LFS tracked)
```

## Security

- Only users with write permissions can accept images
- All operations are logged and attributed
- Git LFS ensures large files don't bloat repository history

## Example Test Script

See `generate_test_images.py` for a sample implementation that creates test images with consistent, reproducible content.

## Troubleshooting

### Images Not Displaying in PR Comments

The workflow uses GitHub Actions artifacts to store comparison images since direct embedding isn't supported by GitHub's security model.

**Expected behavior:**
- PR comments contain detailed comparison summaries and statistics
- Images are available for download via workflow artifacts
- Manual review process provides comprehensive comparison instructions

**If you need to view images:**
1. Click the artifact download link in the PR comment
2. Download the `visual-test-results-[scenario]-[number]` artifact  
3. Extract the ZIP file to access:
   - `outputs/` - New test images generated by your changes
   - `diffs/` - Visual difference highlights (red areas show changes)
   - `golden/` - Current golden master images for comparison
   - `comparison_report.md` - Complete comparison report

**Why not direct display:**
- GitHub Actions artifacts are stored as ZIP files and require authentication
- External image hosting (like gists) can be unreliable due to API limits
- This artifact-based approach works consistently across all repository types

### No Comment Posted

**If no PR comment appears after running visual diff:**
1. Check the workflow logs for any step failures
2. Verify the workflow completed successfully
3. Look for the "Comment PR with results" or "Comment PR with success" steps
4. For private repositories, ensure the workflow has proper permissions

### Download Artifacts

**To download artifacts manually:**
1. Go to the Actions tab in your repository
2. Find the workflow run for your PR
3. Scroll to the "Artifacts" section at the bottom
4. Click the artifact name to download the ZIP file

### Permission Denied on Accept

Ensure the user commenting has write access to the repository.

**Error message:** "does not have write permissions to accept images"
- Only repository collaborators with write or admin access can accept images
- Check repository settings ‚Üí Manage access

### Workflow Not Triggering

Check that:
- The PR has changes that would generate new output images
- The `generate_test_images.py` script runs successfully
- Artifacts are being uploaded correctly

### Git LFS Issues

**Large repository size:**
- Ensure `.gitattributes` is configured correctly
- Verify LFS is tracking image files: `git lfs ls-files`
- Clean up old LFS objects: `git lfs prune`

**LFS file not found:**
- Run `git lfs pull` to download LFS files
- Check LFS quota in repository settings

### Debug Steps

1. **Check workflow logs** for detailed error messages
2. **Download artifacts** manually to verify image generation
3. **Test locally** by running `generate_test_images.py`
4. **Verify permissions** using repository settings
5. **Check branch protection** rules that might block automated commits
